{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq_-Smt7vrx1",
        "outputId": "02787b8b-75f5-4923-a4cc-6fabf864bcf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "from time import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def create_matrix(n):\n",
        "  a = np.random.randint(0, 10, (n, n))\n",
        "  b = np.random.randint(0, 10, (n, n))\n",
        "  c = np.zeros((n, n))\n",
        "  return a, b, c\n",
        "\n",
        "def mul_cpu_element(a, b):\n",
        "  n=len(a)\n",
        "  c = np.zeros((n,n))\n",
        "  start = time()\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      for k in range(n):\n",
        "        c[i, j] += a[i,k] * b[k,j]\n",
        "  return c, time()-start\n",
        "    \n",
        "def mul_cpu_vector(a, b):\n",
        "  n=len(a)\n",
        "  c = np.zeros((n,n))\n",
        "  start = time()\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      c[i, j] = np.dot(a[i,:], b[:,j])\n",
        "  return c, time()-start\n",
        "\n",
        "def mul_cpu_matrix(a, b):\n",
        "  start = time()\n",
        "  c = np.dot(a, b)\n",
        "  return c, time() - start\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_operation(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_operation(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_element(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_vector(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    tmp = 0\n",
        "    for k in range(a.shape[1]):\n",
        "      tmp += a[i, k] * b[k, j]\n",
        "    c[i, j] = tmp\n",
        "\n",
        "def prepare_and_exec_gpu_mul(a, b, c, n, gpu_func):\n",
        "  tread_number_block = 32\n",
        "\n",
        "  a_global = cuda.to_device(a)\n",
        "  b_global = cuda.to_device(b)\n",
        "  c_global = cuda.device_array((n, n))\n",
        "    \n",
        "  threadsperblock = (tread_number_block, tread_number_block)\n",
        "  blockspergrid_x = int(math.ceil(a.shape[0] / threadsperblock[1]))\n",
        "  blockspergrid_y = int(math.ceil(b.shape[1] / threadsperblock[0]))\n",
        "  blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "  start = time()\n",
        "  gpu_func[blockspergrid, threadsperblock](a_global, b_global, c_global)\n",
        "  gpu_time = time() - start\n",
        "  c_gpu = c_global.copy_to_host() \n",
        "  return c_gpu, gpu_time\n",
        "\n",
        "def expiriens(n, count, cpu_func, gpu_func, message):  \n",
        "  gpu_time_sum = 0\n",
        "  cpu_time_sum = 0\n",
        "  for _ in range(count):\n",
        "    a, b, c = create_matrix(n)\n",
        "    c_gpu, gpu_time = prepare_and_exec_gpu_mul(a, b, c, n, gpu_func)\n",
        "    gpu_time_sum+=gpu_time\n",
        "    c_cpu, cpu_time = cpu_func(a, b)\n",
        "    cpu_time_sum+=cpu_time\n",
        "\n",
        "  print(f'Выполнился эксперимент для матрицы размерности {n:d} ({gpu_time_sum+cpu_time_sum:0.6f}) - {message:s}')\n",
        "  return n, cpu_time/count, gpu_time/count, cpu_time/gpu_time\n",
        "\n",
        "def functions_are_correct(n, cpu_func, gpu_func, message):\n",
        "  a, b, c = create_matrix(n)\n",
        "  c_numpy = mul_cpu_matrix(a,b)[0]\n",
        "  c_cpu = cpu_func(a,b)[0]\n",
        "  c_gpu = prepare_and_exec_gpu_mul(a, b, c, n, gpu_func)[0]\n",
        "  if np.array_equal(c_numpy, c_cpu):\n",
        "    print('CPU считает корректно (', message, ')')\n",
        "  if np.array_equal(c_numpy, c_gpu):\n",
        "    print('GPU считает корректно (', message, ')')\n",
        "\n",
        "def build_str(values, msg):\n",
        "  pstr = f'|{msg:s}\\t|'\n",
        "  for val in values:\n",
        "    pstr+=f'{val:0.6f}\\t|'\n",
        "  return pstr\n",
        "\n",
        "def print_table(values, message, names):\n",
        "  up = '|'\n",
        "  for _ in range(len(values)):\n",
        "    up+='\\t'\n",
        "  up+=message\n",
        "  for _ in range(len(values)):\n",
        "    up+='\\t'\n",
        "  up+='|'\n",
        "  print(up)\n",
        "  for j in range(len(names)):\n",
        "    print(build_str([values[i][j] for i in range(len(values))], names[j]))\n",
        "\n",
        "\n",
        "def lab(cpu_func, gpu_func, message, count):\n",
        "  print(message)\n",
        "  a, b, c = create_matrix(128)\n",
        "  functions_are_correct(128, cpu_func, gpu_func, message)\n",
        "  n_array = [100, 128, 256, 512, 750, 1024, 1500, 2048]\n",
        "  values_array = [expiriens(n_array_i, count, cpu_func, gpu_func, message) for n_array_i in n_array]\n",
        "  names = ['Размерность', 'CPU время', 'GPU время', 'Ускорение']\n",
        "  print_table(values_array, message, names)\n",
        "  speed_up_array = [values_array[i][3] for i in range(len(n_array))]\n",
        "  plt.plot(np.array(n_array), np.array(speed_up_array))\n",
        "  plt.xlabel('Размерность')\n",
        "  plt.ylabel('Ускорение')\n",
        "  plt.title(message)\n",
        "  plt.show()\n",
        "\n",
        "lab(mul_cpu_vector, gpu_mul_vector, 'векторное умножение', 1)\n",
        "lab(mul_cpu_element, gpu_mul_element, 'поэлементное умножение', 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "векторное умножение\n",
            "CPU считает корректно ( векторное умножение )\n",
            "GPU считает корректно ( векторное умножение )\n",
            "Выполнился эксперимент для матрицы размерности 100 (0.019296) - векторное умножение\n",
            "Выполнился эксперимент для матрицы размерности 128 (0.030261) - векторное умножение\n",
            "Выполнился эксперимент для матрицы размерности 256 (0.140167) - векторное умножение\n",
            "Выполнился эксперимент для матрицы размерности 512 (0.913804) - векторное умножение\n",
            "Выполнился эксперимент для матрицы размерности 750 (1.560513) - векторное умножение\n",
            "Выполнился эксперимент для матрицы размерности 1024 (5.569338) - векторное умножение\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
